<h1 align="center">ğŸ” ML-Stat-House-Price-Predictor</h1>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue" alt="Python" />
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License" />
  <img src="https://img.shields.io/badge/Made%20with-%E2%9D%A4-red" alt="Love" />
</p>

---

## ğŸ“Œ Table of Contents
- [Why This Project Matters](#why-this-project-matters)
- [Highlights](#highlights)
- [Data Overview](#data-overview)
- [Key Achievements](#key-achievements)
- [Tech Stack](#tech-stack)
- [Methodology](#methodology)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ§  Why This Project Matters
Accurate house price prediction guides investment strategy, city planning, and public policy.  
This project explores how traditional statistical approaches perform compared to modern machine learning techniquesâ€”uncovering which model delivers higher accuracy and better generalizability across diverse datasets.

---

## âœ¨ Highlights
- ğŸ“ˆ Achieved **90%+ RÂ²** on the Boston dataset with tuned **XGBoost**, reducing RMSE by **40%** compared to linear baselines.  
- ğŸ§ª Built a complete pipeline: **data cleaning â†’ feature engineering â†’ model training â†’ evaluation â†’ visualization**.  
- ğŸ› ï¸ Benchmarked five models: `Linear`, `Ridge`, `KNN`, `Random Forest`, and `XGBoost`â€”with and without hyperparameter tuning.

---

## ğŸ—ƒï¸ Data Overview
- **California Housing:** `20,640` rows Â· `10` features  
- **Boston Housing:** `506` rows Â· `13` features  
- ğŸ” Features include geographic coordinates, median income, total rooms, proximity to ocean, etc.

---

## ğŸ† Key Achievements
- ğŸ““ Organized reusable Python scripts & Jupyter notebooks for **reproducibility**.  
- ğŸ§¹ Performed missing-value imputation, outlier detection, one-hot encoding, and log transformation.  
- âš™ï¸ Tuned `Random Forest` & `XGBoost` using `GridSearchCV` for optimal performance.  
- ğŸ“Š Created compelling visualizations: heatmaps, Q-Q plots, residual analysis, and model comparison charts.

---

## ğŸ§° Tech Stack

| Tool         | Role                    |
|--------------|-------------------------|
| ğŸ Python 3.8+ | Programming Language   |
| ğŸ“¦ pandas, NumPy | Data Manipulation     |
| ğŸ¯ scikit-learn | ML & Statistical Models |
| âš¡ XGBoost      | Gradient Boosting      |
| ğŸ“ˆ matplotlib, seaborn | Visualization   |
| ğŸ““ Jupyter Notebook | Interactive Analysis |

---

## ğŸ”¬ Methodology

### 1ï¸âƒ£ ğŸ“Š Data Preprocessing
- Imputed missing bedroom values with mean  
- Detected outliers using IQR & visual inspection  
- Log-transformed skewed features (Boston dataset)  
- One-hot encoded categorical data (e.g., ocean proximity)  
- Split dataset into `80% training / 20% testing`

### 2ï¸âƒ£ ğŸ§  Model Building
- **Statistical Models:**  
  - Linear Regression (OLS & Gradient Descent)  
  - Ridge Regression  
- **Machine Learning Models:**  
  - K-Nearest Neighbors  
  - Random Forest  
  - XGBoost  
- Applied `GridSearchCV` for hyperparameter tuning

### 3ï¸âƒ£ ğŸ§ª Evaluation
- **Metrics:**  
  - Mean Squared Error (MSE)  
  - Root Mean Squared Error (RMSE)  
  - RÂ² Score  
- **Visualization:**  
  - Q-Q & residual plots  
  - Predicted vs actual scatter plots  
  - Bar charts for model comparison

---

## ğŸ¤ Contributing

Contributions are welcome!  

ğŸš€ To get started:
1. Fork the repo  
2. Create a new branch: `git checkout -b feature/YourFeature`  
3. Make your changes  
4. Commit: `git commit -m "Add YourFeature"`  
5. Push: `git push origin feature/YourFeature`  
6. Open a Pull Request

Please follow [PEP8](https://peps.python.org/pep-0008/) and document new features clearly.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for details.

---

<p align="center">
  <b>ğŸ“Š Built with data, models & a passion for insights ğŸ“Š</b>
</p>
