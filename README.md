# ğŸ” ML-Stat-House-Price-Predictor

**A comparative analysis of machine learning and statistical models to predict house prices across Boston and California datasets.**

---

## ğŸ§  Why This Project Matters

Accurate house price prediction guides investment strategy, city planning, and public policy. This project explores how traditional statistical approaches perform compared to modern machine learning techniquesâ€”uncovering which model delivers higher accuracy and better generalizability across diverse datasets.

---

## âœ¨ Highlights

- ğŸ“ˆ Achieved **90%+ RÂ²** on the Boston dataset with tuned **XGBoost**, reducing RMSE by **40%** compared to linear baselines  
- ğŸ§ª Built a complete pipeline: **data cleaning â†’ feature engineering â†’ model training â†’ evaluation â†’ visualization**  
- ğŸ› ï¸ Benchmarked five models: `Linear`, `Ridge`, `KNN`, `Random Forest`, and `XGBoost`â€”with and without hyperparameter tuning  

---

## ğŸ—ƒï¸ Data Overview

- **California Housing**: 20,640 rows Â· 10 features  
- **Boston Housing**: 506 rows Â· 13 features  
- ğŸ” Features include: geographic coordinates, median income, total rooms, proximity to ocean, etc.

---

## ğŸ† Key Achievements

- ğŸ““ Organized reusable Python scripts & Jupyter notebooks for reproducibility  
- ğŸ§¹ Performed missing-value imputation, outlier detection, one-hot encoding, and log transformation  
- âš™ï¸ Tuned `Random Forest` & `XGBoost` using `GridSearchCV` for optimal performance  
- ğŸ“Š Created compelling visualizations: heatmaps, Q-Q plots, residual analysis, model comparison charts  

---

## ğŸ§° Tech Stack

| Tool         | Role                  |
|--------------|------------------------|
| ğŸ Python 3.8+ | Programming Language  |
| ğŸ“¦ pandas, NumPy | Data Manipulation    |
| ğŸ¯ scikit-learn | ML & Statistical Models |
| âš¡ XGBoost      | Gradient Boosting     |
| ğŸ“ˆ matplotlib, seaborn | Visualization  |
| ğŸ““ Jupyter Notebook | Interactive Analysis |

---

## ğŸ”¬ Methodology

### 1. ğŸ“Š Data Preprocessing
- Imputed missing bedroom values with mean  
- Detected outliers using IQR and visual inspection  
- Log-transformed skewed features (Boston dataset)  
- One-hot encoded categorical data (e.g., ocean proximity)  
- Split dataset into 80% training and 20% testing  

### 2. ğŸ§  Model Building
- **Statistical Models**  
  - Linear Regression (OLS & Gradient Descent)  
  - Ridge Regression  

- **Machine Learning Models**  
  - K-Nearest Neighbors  
  - Random Forest  
  - XGBoost  

- Applied `GridSearchCV` for hyperparameter tuning

### 3. ğŸ§ª Evaluation
- Metrics:  
  - Mean Squared Error (MSE)  
  - Root Mean Squared Error (RMSE)  
  - RÂ² Score  

- Visualization:  
  - Q-Q and residual plots  
  - Scatter plots (predicted vs actual)  
  - Bar charts for metric comparison  

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repo  
2. Create a new branch: `git checkout -b feature/YourFeature`  
3. Make your changes  
4. Commit: `git commit -m "Add YourFeature"`  
5. Push: `git push origin feature/YourFeature`  
6. Open a Pull Request

Please follow [PEP8](https://peps.python.org/pep-0008/) and document new features clearly.

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
